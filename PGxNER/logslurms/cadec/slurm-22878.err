pre. tgt. for `dev`:   0%|          | 0/1097 [00:00<?, ?it/s]pre. tgt. for `dev`:  14%|█▎        | 149/1097 [00:00<00:00, 1485.87it/s]pre. tgt. for `dev`:  30%|██▉       | 326/1097 [00:00<00:00, 1652.76it/s]pre. tgt. for `dev`:  46%|████▌     | 504/1097 [00:00<00:00, 1709.63it/s]pre. tgt. for `dev`:  63%|██████▎   | 692/1097 [00:00<00:00, 1773.45it/s]pre. tgt. for `dev`:  80%|███████▉  | 877/1097 [00:00<00:00, 1799.33it/s]pre. tgt. for `dev`:  97%|█████████▋| 1066/1097 [00:00<00:00, 1829.79it/s]                                                                          pre. tgt. for `test`:   0%|          | 0/1160 [00:00<?, ?it/s]pre. tgt. for `test`:  17%|█▋        | 201/1160 [00:00<00:00, 2003.31it/s]pre. tgt. for `test`:  35%|███▍      | 402/1160 [00:00<00:00, 1948.11it/s]pre. tgt. for `test`:  52%|█████▏    | 599/1160 [00:00<00:00, 1951.05it/s]pre. tgt. for `test`:  69%|██████▊   | 795/1160 [00:00<00:00, 1934.26it/s]pre. tgt. for `test`:  85%|████████▌ | 989/1160 [00:00<00:00, 1855.35it/s]                                                                          pre. tgt. for `train`:   0%|          | 0/5340 [00:00<?, ?it/s]pre. tgt. for `train`:   4%|▎         | 189/5340 [00:00<00:02, 1882.72it/s]pre. tgt. for `train`:   7%|▋         | 378/5340 [00:00<00:02, 1803.09it/s]pre. tgt. for `train`:  10%|█         | 559/5340 [00:00<00:02, 1785.46it/s]pre. tgt. for `train`:  14%|█▍        | 755/5340 [00:00<00:02, 1852.24it/s]pre. tgt. for `train`:  18%|█▊        | 951/5340 [00:00<00:02, 1888.26it/s]pre. tgt. for `train`:  21%|██▏       | 1141/5340 [00:00<00:02, 1847.39it/s]pre. tgt. for `train`:  25%|██▌       | 1342/5340 [00:00<00:02, 1898.10it/s]pre. tgt. for `train`:  29%|██▊       | 1533/5340 [00:00<00:02, 1844.61it/s]pre. tgt. for `train`:  32%|███▏      | 1723/5340 [00:00<00:01, 1859.46it/s]pre. tgt. for `train`:  36%|███▌      | 1911/5340 [00:01<00:01, 1864.41it/s]pre. tgt. for `train`:  40%|███▉      | 2121/5340 [00:01<00:01, 1932.83it/s]pre. tgt. for `train`:  43%|████▎     | 2315/5340 [00:01<00:01, 1919.47it/s]pre. tgt. for `train`:  47%|████▋     | 2516/5340 [00:01<00:01, 1944.92it/s]pre. tgt. for `train`:  51%|█████     | 2731/5340 [00:01<00:01, 2005.00it/s]pre. tgt. for `train`:  55%|█████▍    | 2932/5340 [00:01<00:01, 2004.66it/s]pre. tgt. for `train`:  59%|█████▊    | 3133/5340 [00:01<00:01, 1936.67it/s]pre. tgt. for `train`:  63%|██████▎   | 3346/5340 [00:01<00:01, 1992.79it/s]pre. tgt. for `train`:  66%|██████▋   | 3546/5340 [00:01<00:00, 1884.15it/s]pre. tgt. for `train`:  70%|███████   | 3756/5340 [00:01<00:00, 1945.44it/s]pre. tgt. for `train`:  74%|███████▍  | 3957/5340 [00:02<00:00, 1961.67it/s]pre. tgt. for `train`:  78%|███████▊  | 4155/5340 [00:02<00:00, 1923.37it/s]pre. tgt. for `train`:  82%|████████▏ | 4369/5340 [00:02<00:00, 1985.00it/s]pre. tgt. for `train`:  86%|████████▌ | 4569/5340 [00:02<00:00, 1901.41it/s]pre. tgt. for `train`:  89%|████████▉ | 4761/5340 [00:02<00:00, 1891.96it/s]pre. tgt. for `train`:  93%|█████████▎| 4974/5340 [00:02<00:00, 1957.06it/s]pre. tgt. for `train`:  97%|█████████▋| 5171/5340 [00:02<00:00, 1935.82it/s]                                                                            Traceback (most recent call last):
  File "./BARTNER/train.py", line 313, in <module>
    trainer = Trainer(train_data=ds, model=model, optimizer=optimizer,
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/.local/lib/python3.8/site-packages/fastNLP/core/trainer.py", line 559, in __init__
    _check_code(dataset=train_data, model=self.model, losser=losser, forward_func=self._forward_func, metrics=metrics,
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/.local/lib/python3.8/site-packages/fastNLP/core/trainer.py", line 982, in _check_code
    pred_dict = model(**refined_batch_x)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/.conda/envs/new_PGx_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/PGxNER/BARTNER/model/generater.py", line 60, in forward
    return self.seq2seq_model(src_tokens, tgt_tokens, src_seq_len, tgt_seq_len, first)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/.conda/envs/new_PGx_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/PGxNER/BARTNER/model/bart.py", line 281, in forward
    state = self.prepare_state(src_tokens, src_seq_len, first, tgt_seq_len)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/PGxNER/BARTNER/model/bart.py", line 265, in prepare_state
    encoder_outputs, encoder_mask, hidden_states = self.encoder(src_tokens, src_seq_len)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/.conda/envs/new_PGx_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/PGxNER/BARTNER/model/bart.py", line 19, in forward
    mask = seq_len_to_mask(src_seq_len, max_len=src_tokens.size(1))
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/.local/lib/python3.8/site-packages/fastNLP/core/utils.py", line 862, in seq_len_to_mask
    mask = broad_cast_seq_len.lt(seq_len.unsqueeze(1))
RuntimeError: CUDA error: no kernel image is available for execution on the device
