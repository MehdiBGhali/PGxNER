Running on sh04
# conda environments:
#
base                  *  /opt/conda
PGx_env                  /usr/users/rattrapagemehdibenghali/benghali_meh/.conda/envs/PGx_env
PGx_env_37               /usr/users/rattrapagemehdibenghali/benghali_meh/.conda/envs/PGx_env_37
clean_PGx_env            /usr/users/rattrapagemehdibenghali/benghali_meh/.conda/envs/clean_PGx_env
clean_PGx_env_latest_transformers     /usr/users/rattrapagemehdibenghali/benghali_meh/.conda/envs/clean_PGx_env_latest_transformers
cloned_env               /usr/users/rattrapagemehdibenghali/benghali_meh/.conda/envs/cloned_env
final_PGx_env            /usr/users/rattrapagemehdibenghali/benghali_meh/.conda/envs/final_PGx_env
new_PGx_env              /usr/users/rattrapagemehdibenghali/benghali_meh/.conda/envs/new_PGx_env
torch_from_source_env     /usr/users/rattrapagemehdibenghali/benghali_meh/.conda/envs/torch_from_source_env

Namespace(bart_name='facebook/bart-large', batch_size=8, dataset_name='PGxCorpus', decoder_type='avg_feature', eval_start_epoch=10, history_dir='./training_history', length_penalty=1, lr=1e-05, max_len=10, max_len_a=1.6, n_epochs=100, num_beams=3, save_model=1, schedule='linear', target_type='span', use_encoder_mlp=1, warmup_ratio=0.01)
Save cache to caches/data_facebook/bart-large_PGxCorpus_span.pt.
The number of tokens in tokenizer  50265
50275 50280
11.7
True
cuda
