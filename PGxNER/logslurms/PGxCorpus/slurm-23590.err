pre. tgt. for `dev`:   0%|          | 0/75 [00:00<?, ?it/s]pre. tgt. for `dev`:  64%|██████▍   | 48/75 [00:00<00:00, 472.63it/s]                                                                     pre. tgt. for `test`:   0%|          | 0/76 [00:00<?, ?it/s]pre. tgt. for `test`:  66%|██████▌   | 50/76 [00:00<00:00, 496.75it/s]                                                                      pre. tgt. for `train`:   0%|          | 0/567 [00:00<?, ?it/s]pre. tgt. for `train`:   8%|▊         | 44/567 [00:00<00:01, 437.58it/s]pre. tgt. for `train`:  17%|█▋        | 97/567 [00:00<00:01, 460.80it/s]pre. tgt. for `train`:  26%|██▌       | 145/567 [00:00<00:00, 465.36it/s]pre. tgt. for `train`:  35%|███▌      | 201/567 [00:00<00:00, 489.19it/s]pre. tgt. for `train`:  45%|████▍     | 255/567 [00:00<00:00, 500.91it/s]pre. tgt. for `train`:  54%|█████▍    | 306/567 [00:00<00:00, 501.38it/s]pre. tgt. for `train`:  63%|██████▎   | 360/567 [00:00<00:00, 511.00it/s]pre. tgt. for `train`:  73%|███████▎  | 414/567 [00:00<00:00, 518.54it/s]pre. tgt. for `train`:  82%|████████▏ | 467/567 [00:00<00:00, 520.20it/s]pre. tgt. for `train`:  91%|█████████▏| 518/567 [00:01<00:00, 508.68it/s]                                                                           0%|          | 0/2880 [00:00<?, ?it/s, loss:{0:<6.5f}]Epoch 1/80:   0%|          | 0/2880 [00:00<?, ?it/s, loss:{0:<6.5f}]Epoch 1/80:   0%|          | 1/2880 [00:06<5:34:10,  6.96s/it, loss:{0:<6.5f}]Epoch 1/80:   0%|          | 1/2880 [00:06<5:34:10,  6.96s/it, loss:12.13595] Epoch 1/80:   0%|          | 2/2880 [00:10<4:39:51,  5.83s/it, loss:12.13595]Epoch 1/80:   0%|          | 2/2880 [00:10<4:39:51,  5.83s/it, loss:10.28850]Epoch 1/80:   0%|          | 3/2880 [00:19<5:32:37,  6.94s/it, loss:10.28850]Epoch 1/80:   0%|          | 3/2880 [00:19<5:32:37,  6.94s/it, loss:8.71216] Epoch 1/80:   0%|          | 4/2880 [00:24<5:03:56,  6.34s/it, loss:8.71216]Epoch 1/80:   0%|          | 4/2880 [00:24<5:03:56,  6.34s/it, loss:10.23828]Epoch 1/80:   0%|          | 5/2880 [00:29<4:38:48,  5.82s/it, loss:10.23828]Epoch 1/80:   0%|          | 5/2880 [00:29<4:38:48,  5.82s/it, loss:6.93894] Epoch 1/80:   0%|          | 6/2880 [00:33<4:17:17,  5.37s/it, loss:6.93894]Epoch 1/80:   0%|          | 6/2880 [00:33<4:17:17,  5.37s/it, loss:6.80465]Epoch 1/80:   0%|          | 7/2880 [00:38<4:04:21,  5.10s/it, loss:6.80465]Epoch 1/80:   0%|          | 7/2880 [00:38<4:04:21,  5.10s/it, loss:7.90817]Epoch 1/80:   0%|          | 8/2880 [00:46<4:53:52,  6.14s/it, loss:7.90817]Epoch 1/80:   0%|          | 8/2880 [00:46<4:53:52,  6.14s/it, loss:5.94072]Epoch 1/80:   0%|          | 9/2880 [00:55<5:38:16,  7.07s/it, loss:5.94072]Epoch 1/80:   0%|          | 9/2880 [00:55<5:38:16,  7.07s/it, loss:5.68148]Epoch 1/80:   0%|          | 10/2880 [01:03<5:43:17,  7.18s/it, loss:5.68148]Epoch 1/80:   0%|          | 10/2880 [01:03<5:43:17,  7.18s/it, loss:5.70318]Epoch 1/80:   0%|          | 11/2880 [01:09<5:24:17,  6.78s/it, loss:5.70318]Epoch 1/80:   0%|          | 11/2880 [01:09<5:24:17,  6.78s/it, loss:5.33798]Epoch 1/80:   0%|          | 12/2880 [01:18<5:58:50,  7.51s/it, loss:5.33798]Epoch 1/80:   0%|          | 12/2880 [01:18<5:58:50,  7.51s/it, loss:5.04661]Epoch 1/80:   0%|          | 13/2880 [01:25<5:48:38,  7.30s/it, loss:5.04661]Epoch 1/80:   0%|          | 13/2880 [01:25<5:48:38,  7.30s/it, loss:4.92851]Epoch 1/80:   0%|          | 14/2880 [01:29<5:03:07,  6.35s/it, loss:4.92851]Epoch 1/80:   0%|          | 14/2880 [01:29<5:03:07,  6.35s/it, loss:4.74420]Epoch 1/80:   1%|          | 15/2880 [01:33<4:36:44,  5.80s/it, loss:4.74420]Epoch 1/80:   1%|          | 15/2880 [01:33<4:36:44,  5.80s/it, loss:4.59026]Epoch 1/80:   1%|          | 16/2880 [01:37<4:02:38,  5.08s/it, loss:4.59026]Epoch 1/80:   1%|          | 16/2880 [01:37<4:02:38,  5.08s/it, loss:4.56307]Epoch 1/80:   1%|          | 17/2880 [01:41<3:45:49,  4.73s/it, loss:4.56307]Epoch 1/80:   1%|          | 17/2880 [01:41<3:45:49,  4.73s/it, loss:4.56122]Epoch 1/80:   1%|          | 18/2880 [01:45<3:36:28,  4.54s/it, loss:4.56122]Epoch 1/80:   1%|          | 18/2880 [01:45<3:36:28,  4.54s/it, loss:4.52184]Epoch 1/80:   1%|          | 19/2880 [01:49<3:31:58,  4.45s/it, loss:4.52184]Epoch 1/80:   1%|          | 19/2880 [01:49<3:31:58,  4.45s/it, loss:4.09294]Epoch 1/80:   1%|          | 20/2880 [01:54<3:39:57,  4.61s/it, loss:4.09294]Epoch 1/80:   1%|          | 20/2880 [01:54<3:39:57,  4.61s/it, loss:4.39851]Epoch 1/80:   1%|          | 21/2880 [02:00<4:03:52,  5.12s/it, loss:4.39851]Epoch 1/80:   1%|          | 21/2880 [02:00<4:03:52,  5.12s/it, loss:4.24293]Epoch 1/80:   1%|          | 22/2880 [02:06<4:09:28,  5.24s/it, loss:4.24293]Epoch 1/80:   1%|          | 22/2880 [02:06<4:09:28,  5.24s/it, loss:4.31293]Epoch 1/80:   1%|          | 23/2880 [02:11<4:07:06,  5.19s/it, loss:4.31293]Epoch 1/80:   1%|          | 23/2880 [02:11<4:07:06,  5.19s/it, loss:4.69540]Epoch 1/80:   1%|          | 24/2880 [02:14<3:44:32,  4.72s/it, loss:4.69540]Epoch 1/80:   1%|          | 24/2880 [02:14<3:44:32,  4.72s/it, loss:4.17547]Epoch 1/80:   1%|          | 25/2880 [02:18<3:30:48,  4.43s/it, loss:4.17547]Epoch 1/80:   1%|          | 25/2880 [02:18<3:30:48,  4.43s/it, loss:3.84391]Epoch 1/80:   1%|          | 26/2880 [02:22<3:17:03,  4.14s/it, loss:3.84391]Epoch 1/80:   1%|          | 26/2880 [02:22<3:17:03,  4.14s/it, loss:3.99185]Epoch 1/80:   1%|          | 27/2880 [02:25<3:10:52,  4.01s/it, loss:3.99185]Epoch 1/80:   1%|          | 27/2880 [02:25<3:10:52,  4.01s/it, loss:3.87491]Epoch 1/80:   1%|          | 28/2880 [02:29<3:12:25,  4.05s/it, loss:3.87491]Epoch 1/80:   1%|          | 28/2880 [02:29<3:12:25,  4.05s/it, loss:3.94409]Epoch 1/80:   1%|          | 29/2880 [02:34<3:18:14,  4.17s/it, loss:3.94409]Epoch 1/80:   1%|          | 29/2880 [02:34<3:18:14,  4.17s/it, loss:4.08849]Epoch 1/80:   1%|          | 30/2880 [02:38<3:20:28,  4.22s/it, loss:4.08849]Epoch 1/80:   1%|          | 30/2880 [02:38<3:20:28,  4.22s/it, loss:3.84971]Epoch 1/80:   1%|          | 31/2880 [02:44<3:43:19,  4.70s/it, loss:3.84971]Epoch 1/80:   1%|          | 31/2880 [02:44<3:43:19,  4.70s/it, loss:3.70478]Epoch 1/80:   1%|          | 32/2880 [02:50<3:57:03,  4.99s/it, loss:3.70478]Epoch 1/80:   1%|          | 32/2880 [02:50<3:57:03,  4.99s/it, loss:3.82919]Epoch 1/80:   1%|          | 33/2880 [03:01<5:29:43,  6.95s/it, loss:3.82919]Epoch 1/80:   1%|          | 33/2880 [03:01<5:29:43,  6.95s/it, loss:4.08790]Epoch 1/80:   1%|          | 34/2880 [03:11<6:13:27,  7.87s/it, loss:4.08790]Epoch 1/80:   1%|          | 34/2880 [03:11<6:13:27,  7.87s/it, loss:3.89487]Epoch 1/80:   1%|          | 35/2880 [03:17<5:38:00,  7.13s/it, loss:3.89487]Epoch 1/80:   1%|          | 35/2880 [03:17<5:38:00,  7.13s/it, loss:3.90572]Epoch 1/80:   1%|▏         | 36/2880 [03:19<4:30:03,  5.70s/it, loss:3.90572]Epoch 1/80:   1%|▏         | 36/2880 [03:19<4:30:03,  5.70s/it, loss:3.39732]Epoch 2/80:   1%|▏         | 36/2880 [03:19<4:30:03,  5.70s/it, loss:3.39732]Epoch 2/80:   1%|▏         | 37/2880 [03:34<6:47:26,  8.60s/it, loss:3.39732]Epoch 2/80:   1%|▏         | 37/2880 [03:34<6:47:26,  8.60s/it, loss:4.04341]Epoch 2/80:   1%|▏         | 38/2880 [03:39<5:56:28,  7.53s/it, loss:4.04341]Epoch 2/80:   1%|▏         | 38/2880 [03:39<5:56:28,  7.53s/it, loss:3.61667]                                                                             Traceback (most recent call last):
  File "./BARTNER/train.py", line 332, in <module>
    trainer.train(load_best_model=False)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/.local/lib/python3.8/site-packages/fastNLP/core/trainer.py", line 667, in train
    raise e
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/.local/lib/python3.8/site-packages/fastNLP/core/trainer.py", line 658, in train
    self._train()
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/.local/lib/python3.8/site-packages/fastNLP/core/trainer.py", line 718, in _train
    prediction = self._data_forward(self.model, batch_x)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/.local/lib/python3.8/site-packages/fastNLP/core/trainer.py", line 821, in _data_forward
    y = network(**x)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/conda_env/pytorch/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/PGxNER/BARTNER/model/generater.py", line 60, in forward
    return self.seq2seq_model(src_tokens, tgt_tokens, src_seq_len, tgt_seq_len, first)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/conda_env/pytorch/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/PGxNER/BARTNER/model/bart.py", line 282, in forward
    decoder_output = self.decoder(tgt_tokens, state)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/conda_env/pytorch/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/PGxNER/BARTNER/model/bart.py", line 165, in forward
    dict = self.decoder(input_ids=tokens,
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/conda_env/pytorch/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/PGxNER/BARTNER/model/modeing_bart.py", line 590, in forward
    x, layer_self_attn, layer_past = decoder_layer(
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/conda_env/pytorch/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/PGxNER/BARTNER/model/modeing_bart.py", line 440, in forward
    x, _ = self.encoder_attn(
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/conda_env/pytorch/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/PGxNER/BARTNER/model/modeing_bart.py", line 690, in forward
    v = self.v_proj(key)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/conda_env/pytorch/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/conda_env/pytorch/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
  File "/usr/users/rattrapagemehdibenghali/benghali_meh/conda_env/pytorch/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 203482) is killed by signal: Killed. 
